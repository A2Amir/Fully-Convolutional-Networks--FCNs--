{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from distutils.version import LooseVersion\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_8():\n",
    "    def __init__(self,data_path='./data/',image_shape=(160,576),num_classes=2,epochs=10,batch_size=20,learning_rate=0.0005,save_model=True):\n",
    "        \n",
    "        self.GPU=self.check_GPU()\n",
    "        self.data_path=data_path\n",
    "        self.TF_version=self.check_version()\n",
    "        self.dataset_folders=self.downlaod_dataset(self.data_path)\n",
    "        self.weights_path=self.downlaod_pretrained_vgg(self.data_path)\n",
    "        self.num_classes=num_classes\n",
    "        self.image_shape=image_shape\n",
    "        self.epochs=epochs\n",
    "        self.batch_size=batch_size\n",
    "        self.save_model=save_model\n",
    "        self.learning_rate=learning_rate\n",
    "\n",
    "        \n",
    "        \n",
    "    def check_version(self):\n",
    "        assert LooseVersion(tf.__version__)>=LooseVersion('1.0'),'Please use Tensorflow version 1.0 or newer. You are using {}'.format(tf.__version__)\n",
    "        return tf.__version__\n",
    "        \n",
    "    def check_GPU(self):\n",
    "        if not tf.test.gpu_device_name():\n",
    "            warnings.warn('Non GPU found. Please use a GPU to train your neural network.')\n",
    "            return False\n",
    "        else:\n",
    "            print('Default GPU Devices{}'.format(tf.test.gpu_device_name()))\n",
    "            return True\n",
    "        \n",
    "    def downlaod_pretrained_vgg(self,path):\n",
    "        \"\"\"\n",
    "        Download and extract pretrained vgg model if doesnt exist\n",
    "        :param path: Directory to downlaod the model to\n",
    "        \"\"\"\n",
    "        vgg_file_name=\"vgg.zip\"\n",
    "        vgg_path=os.path.join(path,'vgg_weights')\n",
    "        vgg_files=[os.path.join(vgg_path,'vgg/variables/variables.data-00000-of-00001'),\n",
    "                  os.path.join(vgg_path,'vgg/variables/variables.index'),\n",
    "                  os.path.join(vgg_path,'vgg/saved_model.pb')]\n",
    "        missing_files=[vgg_file for vgg_file in vgg_files if not os.path.exists(vgg_file)]\n",
    "        #print(missing_files)\n",
    "        if missing_files:\n",
    "            #Clean vgg directory\n",
    "            if os.path.exists(vgg_path):\n",
    "                #clean vgg path\n",
    "                shutil.rmtree(vgg_path)\n",
    "            os.mkdir(vgg_path)\n",
    "            \n",
    "            print('Downloading pretrained vgg nodel...')\n",
    "            with DLProgress(unit='B',unit_scale=True,miniters=1) as pbar:\n",
    "                urlretrieve('https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip',\n",
    "                           os.path.join(path,vgg_file_name),\n",
    "                           pbar.hook)\n",
    "        \n",
    "            #Extract vgg file\n",
    "            zip_ref=zipfile.ZipFile(os.path.join(path,vgg_file_name),'r')\n",
    "            zip_ref.extractall(vgg_path)\n",
    "            zip_ref.close()\n",
    "            os.remove(os.path.join(path, vgg_filename))\n",
    "        else:\n",
    "            print('Vgg weights are available')\n",
    "        return os.path.join(vgg_path,'vgg')         \n",
    "                                \n",
    "                                \n",
    "    def load_vgg(self,sess):\n",
    "        \"\"\"\n",
    "        Load Pretrained VGG Model into TensorFlow\n",
    "        :param sess: TensorFlow Session\n",
    "        :param weights_path: the path to the vgg folder where contains weights variables\n",
    "        :return: Tuple of Tensors from VGG Model(Input Image,Keep_probab,layer3_out,layer4_out,layer7_out)\n",
    "        \"\"\"\n",
    "        vgg_name='vgg16'\n",
    "        vgg_input_tensor_name='image_input:0'\n",
    "        vgg_keep_prob_tensor_name='keep_prob:0'\n",
    "        vgg_layer3_out_tensor_name='layer3_out:0'\n",
    "        vgg_layer4_out_tensor_name='layer4_out:0'\n",
    "        vgg_layer7_out_tensor_name='layer7_out:0'\n",
    "        \n",
    "        tf.saved_model.loader.load(sess,[vgg_name],self.weights_path)\n",
    "        graph=tf.get_default_graph()\n",
    "        image_input=graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "        keep_prob=graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "        layer3_out=graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "        layer4_out=graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "        layer7_out=graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "\n",
    "        return image_input,keep_prob,layer3_out,layer4_out,layer7_out\n",
    "    \n",
    "    def encoder(self,layer7_out,num_classes):\n",
    "        \"\"\"\n",
    "        Create the encoder portion of the FCN \n",
    "        :param layer7_out:TF Tensor for VGG Layer 7 output\n",
    "        :return: tensor for the last layer of the encoder which ic 1 by 1 convolution \n",
    "        \"\"\"\n",
    "        #1*1 conv\n",
    "        conv11_out=tf.layers.conv2d(layer7_out,num_classes,1,\n",
    "                                padding='same',\n",
    "                                kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        return conv11_out\n",
    "    \n",
    "    def decoder(self,conv11_out,layer3_out,layer4_out,num_classes):\n",
    "        \n",
    "        \"\"\"\n",
    "        Create the Eecoder portion of the FCN \n",
    "        :param conv11_out:TF Tensor for last layer of the encoder \n",
    "        :param layer3_out:TF Tensor for VGG Layer 3 output\n",
    "        :param layer4_out:TF Tensor for VGG Layer 4 output\n",
    "        :return: tensor for the last layer of the decoder.\n",
    "        \"\"\"\n",
    "        \n",
    "        #upsample\n",
    "        l8_out=tf.layers.conv2d_transpose(conv11_out,num_classes,4,2,\n",
    "                                         padding='same',\n",
    "                                         kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        # check the shapes\n",
    "        l4=tf.layers.conv2d(layer4_out,num_classes,1,padding='same',\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        # skip connection (element-wise addition)\n",
    "        l9_in=tf.add(l8_out,l4)\n",
    "        \n",
    "        #upsample by 2\n",
    "        l9_out=tf.layers.conv2d_transpose(l9_in,num_classes,4,2,\n",
    "                                         padding='same',\n",
    "                                         kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        \n",
    "        l3=tf.layers.conv2d(layer3_out,num_classes,1,padding='same',\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        # skip connection (element-wise addition)\n",
    "        l10_in=tf.add(l9_out,l3)\n",
    "        \n",
    "        #upsample\n",
    "        ll0_out = tf.layers.conv2d_transpose(l10_in, num_classes, 16, 8,\n",
    "                                    padding='same',\n",
    "                                    kernel_regularizer=tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        \n",
    "        return ll0_out\n",
    "    \n",
    "    def downlaod_dataset(self,path):\n",
    "        \"\"\"\n",
    "        To load data from the the data directory\n",
    "        :param data_folder: path to the folder contains all the dataset\n",
    "        :return :lists of images and ground truths path\n",
    "        \"\"\"\n",
    "        images_path=[]\n",
    "        gt_images_path=[]\n",
    "\n",
    "\n",
    "        dataset_file_name=\"data_road.zip\"\n",
    "        dataset_path=os.path.join(path,'data_road')\n",
    "        dataset_folders=[os.path.join(path,'data_road/data_road/training/image_2/'),\n",
    "                  os.path.join(path,'data_road/data_road/training/gt_image_2/'),\n",
    "                  os.path.join(path,'data_road/data_road/testing/image_2/')]\n",
    "        \n",
    "        missing_folder=[dataset_folder for dataset_folder in dataset_folders if not os.path.exists(dataset_folder)]\n",
    "        #print(missing_folder)\n",
    "        if missing_folder:\n",
    "            #Clean vgg directory\n",
    "            if os.path.exists(dataset_path):\n",
    "                #clean vgg path\n",
    "                shutil.rmtree(dataset_path)\n",
    "            os.mkdir(dataset_path)\n",
    "            \n",
    "            print('Downloading dataset...')\n",
    "            with DLProgress(unit='B',unit_scale=True,miniters=1) as pbar:\n",
    "                urlretrieve('https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip',\n",
    "                           os.path.join(path,dataset_file_name),\n",
    "                           pbar.hook)\n",
    "        \n",
    "            #Extract vgg file\n",
    "            zip_ref=zipfile.ZipFile(os.path.join(path,dataset_file_name),'r')\n",
    "            zip_ref.extractall(dataset_path)\n",
    "            zip_ref.close()\n",
    "            os.remove(os.path.join(path, dataset_file_name))\n",
    "        else:\n",
    "            print('Dataset is available')\n",
    "            \n",
    "          \n",
    "        #gt_images_path={re.sub(r'_(road|lane)_','_',os.path.basename(path)):path for path in }\n",
    "        return dataset_folders\n",
    "    \n",
    "    def generator(self,batch_size,image_shape):\n",
    "        \"\"\"\n",
    "        create batches of training data\n",
    "        :param data_folder: Path to folder that contains all the datasets\n",
    "        :param image_shape: Tuple - Shape of image\n",
    "        :param batch_size: Batch Size\n",
    "        :return: Batches of training data\n",
    "        \"\"\"\n",
    "        train_imgs=glob.glob(self.dataset_folders[0]+ '*.png')\n",
    "        train_gts=glob.glob(self.dataset_folders[1]+ '*_road_*.png')\n",
    "        train_imgs=sorted(train_imgs)\n",
    "        train_gts=sorted(train_gts)\n",
    "        \n",
    "        background_color = np.array([255, 0, 0])\n",
    "        \n",
    "        #Shuffle two list at once with same order\n",
    "        c=list(zip(train_imgs,train_gts))\n",
    "        random.shuffle(c)\n",
    "        train_imgs,train_gts=zip(*c)\n",
    "        \n",
    "        for batch in range(0,len(train_imgs),batch_size):\n",
    "            X_train=[]\n",
    "            y_train=[]\n",
    "            \n",
    "            train_batches=train_imgs[batch:batch+batch_size]\n",
    "            train_Gtbatches=train_gts[batch:batch+batch_size]\n",
    "            \n",
    "            for image_file,gt_image_file in zip(train_batches,train_Gtbatches):\n",
    "                \n",
    "                image = cv2.resize(cv2.cvtColor(cv2.imread(image_file),cv2.COLOR_BGR2RGB), image_shape)\n",
    "                gt_image =cv2.resize(cv2.cvtColor(cv2.imread(gt_image_file),cv2.COLOR_BGR2RGB), image_shape)\n",
    "\n",
    "                gt_bg = np.all(gt_image == background_color, axis=2)\n",
    "\n",
    "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "                \n",
    "                X_train.append(image)\n",
    "                y_train.append(gt_image)\n",
    "\n",
    "            yield np.array(X_train), np.array(y_train)\n",
    "                \n",
    "\n",
    "    def optimize(self,nn_last_layer,correct_label,learning_rate,num_classes):\n",
    "        \n",
    "        \"\"\"\n",
    "        Build the TensorFLow loss and optimizer operations.\n",
    "        :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "        :param correct_label: TF Placeholder for the correct label image\n",
    "        :param learning_rate: TF Placeholder for the learning rate\n",
    "        :param num_classes: Number of classes to classify\n",
    "        :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "        \"\"\"\n",
    "        logits=tf.reshape(nn_last_layer,(-1,num_classes))\n",
    "        fix_label=tf.reshape(correct_label,(-1,num_classes))\n",
    "        cross_entropy_loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=fix_label,logits=logits))\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op=optimizer.minimize(cross_entropy_loss)\n",
    "        return logits,train_op,cross_entropy_loss\n",
    "    \n",
    "        \n",
    "    def train_nn(self,sess,epochs,batch_size,train_op,cross_entropy_loss,\n",
    "                    image_input,image_shape,correct_label,keep_prob,learning_rate):\n",
    "         \n",
    "        \"\"\"\n",
    "        Train neural network and print out the loss during training.\n",
    "        :param sess: TF Session\n",
    "        :param epochs: Number of epochs\n",
    "        :param batch_size: Batch size\n",
    "        :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "        :param train_op: TF Operation to train the neural network\n",
    "        :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "        :param input_image: TF Placeholder for input images\n",
    "        :param correct_label: TF Placeholder for label images\n",
    "        :param keep_prob: TF Placeholder for dropout keep probability\n",
    "        :param learning_rate: TF Placeholder for learning rate\n",
    "        \"\"\"\n",
    "        saver = tf.train.Saver()\n",
    "        model_path=os.path.join(self.data_path,'fcn_model/FCN.ckpt')        #to save model\n",
    "        if not os.path.exists(os.path.dirname(model_path)):\n",
    "            os.mkdir(os.path.dirname(model_path))\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in tqdm(range(epochs)):\n",
    "            print(\"Epoch >>>{}...\".format(i+1))\n",
    "            for image,label in self.generator(batch_size,image_shape):\n",
    "                \n",
    "                _,loss=sess.run([train_op,cross_entropy_loss],feed_dict={image_input:image,correct_label:label,keep_prob: 0.5,\n",
    "                                          learning_rate: self.learning_rate})\n",
    "                print(\"LOSS >>>> {:.3f}\".format(loss))\n",
    "                if self.save_model:\n",
    "                     saver.save(sess, model_path)\n",
    "                \n",
    "        print('Training Finished. Saved the weights to: {}'.format(model_path))  \n",
    "\n",
    "    def gen_test_output(self,sess, logits, keep_prob, image_pl, image_shape):\n",
    "        \"\"\"\n",
    "        Generate test output using the test images and save them\n",
    "        :param sess: TF session\n",
    "        :param logits: TF Tensor for the logits\n",
    "        :param keep_prob: TF Placeholder for the dropout keep robability\n",
    "        :param image_pl: TF Placeholder for the image placeholder\n",
    "        :param image_shape: Tuple - Shape of image\n",
    "        \"\"\"\n",
    "        imgs=glob.glob(self.dataset_folders[2]+ '*.png')\n",
    "        output_dir=os.path.join(self.dataset_folders[2], 'result')\n",
    "        \n",
    "        for img in imgs:\n",
    "            image = cv2.resize(cv2.cvtColor(cv2.imread(img),cv2.COLOR_BGR2RGB), image_shape)\n",
    "\n",
    "            im_softmax = sess.run([tf.nn.softmax(logits)],{keep_prob: 1.0, image_pl: [image]})\n",
    "            print(im_softmax)\n",
    "            print()\n",
    "            print(im_softmax[0][:, 1])\n",
    "\n",
    "            im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "            segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "            mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "            mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "            im = Image.fromarray(A)\n",
    "            street_im = scipy.misc.toimage(image)\n",
    "            street_im.paste(mask, box=None, mask=mask)\n",
    "            plt.imsave(output_dir, image)\n",
    "\n",
    "        \n",
    "        \n",
    "    def run_train(self):\n",
    "            \n",
    "        with tf.Session() as sess:\n",
    "            correct_label=tf.placeholder(tf.int32,[None,None,None,self.num_classes],name='correct_label')\n",
    "            learning_rate=tf.placeholder(tf.float32,name='learning_rate')\n",
    "                \n",
    "            image_input,keep_prob,layer3_out,layer4_out,layer7_out=self.load_vgg(sess)\n",
    "            encoder=self.encoder(layer7_out,self.num_classes)\n",
    "            decoder_last_layer=self.decoder(encoder,layer3_out,layer4_out,self.num_classes)\n",
    "            logits,train_op,cross_entropy_loss=self.optimize(decoder_last_layer,correct_label,learning_rate,self.num_classes)\n",
    "            self.train_nn(sess,self.epochs,self.batch_size,train_op,cross_entropy_loss,\n",
    "                    image_input,self.image_shape,correct_label,keep_prob,learning_rate)  \n",
    "            self.gen_test_output(sess, logits, keep_prob, image_input, self.image_shape)    \n",
    "        \n",
    "class DLProgress(tqdm):\n",
    "    last_bloack=0\n",
    "\n",
    "    def hook(self,block_num=1,block_size=1,total_size=None):\n",
    "        self.total=total_size\n",
    "        self.update((block_num-self.last_bloack)*block_size)\n",
    "        self.last_bloack=block_num   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is available\n",
      "Vgg weights are available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Non GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "fcn=FCN_8(epochs=1,batch_size=40)\n",
    "#print(fcn.dataset_folders)\n",
    "#print(fcn.weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./data/vgg_weights\\vgg\\variables\\variables\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-315b9830bb24>:99: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-315b9830bb24>:116: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-315b9830bb24>:242: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch >>>1...\n"
     ]
    }
   ],
   "source": [
    "fcn.run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
